services:
  web:
    build: ./backend
    command: sh -c "python manage.py collectstatic --noinput && gunicorn config.wsgi:application --bind 0.0.0.0:8015 --log-level debug"
    volumes:
      - ./backend:/usr/src/backend
    ports:
    - "8015:8015"
    env_file:
      - ./.env
    depends_on:
      - db
    networks:
      - config

  db:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=postgresuser
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=djangodb
    networks:
      - config

  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - config
    restart: unless-stopped
    volumes:
    - redis_data:/data
  
  redis-exporter:
    image: oliver006/redis_exporter
    container_name: redis-exporter
    ports:
      - "9121:9121"  # Redis Exporter exposes metrics here
    environment:
      REDIS_ADDR: redis:6379  # Connect Redis Exporter to Redis
    networks:
      - config

  celery:
    build:
      context: ./backend
    container_name: celery
    command: celery -A config worker --loglevel=info
    volumes:
      - ./backend:/usr/src/backend
      - celery_volume:/usr/src/backend/celery
    depends_on:
      - redis
      - kafka
    # user: "celeryuser"
    env_file:
      - ./.env
    networks:
      - config  # Attach celery service to the backend network

  # celery-exporter:
  #   image: richardjkendall/celery-exporter
  #   container_name: celery-exporter
  #   ports:
  #     - "9101:9101"  # Celery Exporter exposes metrics here
  #   environment:
  #     - CELERY_BROKER_URL=kafka://kafka:9092
  #   networks:
  #     - config

    
  celery_beat:
    build:
      context: ./backend
    container_name: celery_beat
    command: celery -A config beat --loglevel=info
    volumes:
      - ./backend:/usr/src/backend
      - celery_beat_volume:/usr/src/backend/celery_beat
    depends_on:
      - redis
      - celery
    # user: "celeryuser"
    env_file:
      - ./.env
    networks:
      - config  # Attach celery_beat service to the backend network

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - config

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168            # Retain messages for 7 days
      KAFKA_LOG_RETENTION_BYTES: 1073741824     # 1GB per partition
      KAFKA_LOG_SEGMENT_BYTES: 1073741824       # Segment size (1GB)
      KAFKA_LOG_CLEANUP_POLICY: delete          # Default cleanup policy
      KAFKA_DELETE_RETENTION_MS: 86400000       # Retain delete markers for 24 hours
      KAFKA_LOG_MESSAGE_TIMESTAMP_TYPE: CreateTime  # Use message creation time for retention

    networks:
      - config

  kafka-exporter:
    image: danielqsj/kafka-exporter
    container_name: kafka-exporter
    ports:
      - "9308:9308"  # Kafka Exporter exposes metrics here
    environment:
      KAFKA_SERVER: kafka:9092  # Connect to Kafka broker
    networks:
      - config
    depends_on:
      - kafka

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - config

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3001:3000"
    networks:
      - config

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    networks:
      - config

volumes:
  postgres_data:
  redis_data:
  celery_volume:  # Added volume for celery
  celery_beat_volume:  # Added volume for celery_beat
  

networks:
  config:
    driver: bridge
